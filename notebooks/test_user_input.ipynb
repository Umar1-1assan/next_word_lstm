{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d96615fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 1: Imports\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from IPython.display import display, Markdown\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567b6cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ../models/best_model.h5 and tokenizer from ../data/processed/tokenizer.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model expects input sequence length: 20\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load trained model and tokenizer\n",
    "MODEL_PATH = '../models/best_model.h5'\n",
    "TOKENIZER_PATH = '../data/processed/tokenizer.pkl'\n",
    "\n",
    "print(f\"Loading model from {MODEL_PATH} and tokenizer from {TOKENIZER_PATH}...\")\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "with open(TOKENIZER_PATH, 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# Determine sequence length from model input\n",
    "seq_length = model.input_shape[1]\n",
    "vocab = tokenizer.word_index\n",
    "inv_vocab = {v:k for k,v in tokenizer.word_index.items()}\n",
    "print(f\"Model expects input sequence length: {seq_length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f6ae160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Prediction function\n",
    "def predict_next_words(seed_text, top_k=3):\n",
    "    \"\"\"\n",
    "    Given a seed_text (string), predict top_k next words and return list of (word, probability).\n",
    "    \"\"\"\n",
    "    # Clean and tokenize seed text\n",
    "    # Convert to lower-case and simple whitespace normalization\n",
    "    text = seed_text.lower().strip()\n",
    "    seq = tokenizer.texts_to_sequences([text])[0]\n",
    "    # Take last seq_length tokens\n",
    "    seq = seq[-seq_length:]\n",
    "    # Pad sequence\n",
    "    seq_padded = pad_sequences([seq], maxlen=seq_length, padding='pre')\n",
    "    # Predict probabilities\n",
    "    preds = model.predict(seq_padded, verbose=0)[0]\n",
    "    # Get top_k indices\n",
    "    top_indices = np.argsort(preds)[-top_k:][::-1]\n",
    "    return [(inv_vocab.get(idx, '<UNK>'), float(preds[idx])) for idx in top_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c78bfd55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Next-Word Prediction CLI"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 predictions:\n",
      "  of — 4.81%\n",
      "  and — 2.92%\n",
      "  ii — 2.35%\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Single-run CLI testing\n",
    "# Prompt the user once for input, predict, then exit\n",
    "display(Markdown(\"### Next-Word Prediction CLI\"))\n",
    "seed = input(\"Enter a seed phrase: \")\n",
    "# You could handle 'exit' if needed, but this runs once per invocation\n",
    "predictions = predict_next_words(seed, top_k=3)\n",
    "print(\"Top-3 predictions:\")\n",
    "for word, prob in predictions:\n",
    "    print(f\"  {word} — {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a2e3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
