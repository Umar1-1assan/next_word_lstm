{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5149f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from math import exp\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca5cca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model expecting seq_length=20, vocab_size=25759\n"
     ]
    }
   ],
   "source": [
    "# Load model, tokenizer, and data\n",
    "MODEL_PATH = '../models/best_model.h5'\n",
    "TOKENIZER_PATH = '../data/processed/tokenizer.pkl'\n",
    "X = np.load('../data/processed/data_X.npy')\n",
    "y = np.load('../data/processed/data_y.npy')\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "with open(TOKENIZER_PATH, 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "inv_vocab = {i: w for w, i in tokenizer.word_index.items()}\n",
    "seq_length = model.input_shape[1]\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(f\"Loaded model expecting seq_length={seq_length}, vocab_size={vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction helper functions\n",
    "def predict_next(seed, top_k=3):\n",
    "    \"\"\"Return top_k (word, prob) given a seed text.\"\"\"\n",
    "    seq = tokenizer.texts_to_sequences([seed.lower()])[0]\n",
    "    seq = seq[-seq_length:]\n",
    "    padded = pad_sequences([seq], maxlen=seq_length)\n",
    "    probs = model.predict(padded, verbose=0)[0]\n",
    "    idxs = np.argsort(probs)[-top_k:][::-1]\n",
    "    return [(inv_vocab.get(i, '<UNK>'), probs[i]) for i in idxs]\n",
    "\n",
    "\n",
    "def generate_text(seed, length=10):\n",
    "    \"\"\"Generate a continuation of `length` words by feeding back predictions.\"\"\"\n",
    "    result = seed.split()\n",
    "    for _ in range(length):\n",
    "        pred = predict_next(' '.join(result))\n",
    "        next_word = pred[0][0]\n",
    "        result.append(next_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fceb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Shakespearean Coherence Tests\n",
      "Seed: to be or not to\n",
      "Next words: [('be', np.float32(0.039063923)), ('the', np.float32(0.018615661)), ('make', np.float32(0.012967142))]\n",
      "Continuation: to be or not to be the king of the\n",
      "\n",
      "Seed: friends romans countrymen lend\n",
      "Next words: [('me', np.float32(0.1385538)), ('him', np.float32(0.05157193)), ('them', np.float32(0.037278906))]\n",
      "Continuation: friends romans countrymen lend me the king and the\n",
      "\n",
      "Seed: o romeo romeo wherefore art\n",
      "Next words: [('thou', np.float32(0.79819345)), ('i', np.float32(0.04851988)), ('you', np.float32(0.03971749))]\n",
      "Continuation: o romeo romeo wherefore art thou a man that thou\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate coherence on Shakespearean seeds\n",
    "shakespeare_seeds = [\n",
    "    \"to be or not to\",\n",
    "    \"friends romans countrymen lend\",\n",
    "    \"o romeo romeo wherefore art\"\n",
    "]\n",
    "print(\"### Shakespearean Coherence Tests\")\n",
    "for seed in shakespeare_seeds:\n",
    "    print(f\"Seed: {seed}\")\n",
    "    print(\"Next words:\", predict_next(seed))\n",
    "    print(\"Continuation:\", generate_text(seed, length=5))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Custom Input Tests\n",
      "Seed: in a galaxy far away\n",
      "Next words: [('and', np.float32(0.092671275)), ('in', np.float32(0.02969546)), ('to', np.float32(0.02868353))]\n",
      "\n",
      "Seed: the quick brown fox\n",
      "Next words: [('and', np.float32(0.16170955)), ('of', np.float32(0.07763309)), ('that', np.float32(0.04280298))]\n",
      "\n",
      "Seed: machine learning is\n",
      "Next words: [('the', np.float32(0.056452557)), ('not', np.float32(0.0493109)), ('in', np.float32(0.02187959))]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Coherence on custom inputs\n",
    "custom_seeds = [\n",
    "    \"in a galaxy far away\",\n",
    "    \"the quick brown fox\",\n",
    "    \"machine learning is\"\n",
    "]\n",
    "print(\"### Custom Input Tests\")\n",
    "for seed in custom_seeds:\n",
    "    print(f\"Seed: {seed}\")\n",
    "    print(\"Next words:\", predict_next(seed))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8298f407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity on validation (10k samples): 541.74\n"
     ]
    }
   ],
   "source": [
    "# Generalization: compute perplexity on held-out split\n",
    "split = int(0.9 * len(X))\n",
    "X_val, y_val = X[split:], y[split:]\n",
    "\n",
    "def compute_perplexity(X_data, y_data):\n",
    "    log_probs = []\n",
    "    # batch inference\n",
    "    preds = model.predict(X_data, verbose=0)\n",
    "    for i, true_idx in enumerate(y_data):\n",
    "        prob = preds[i, true_idx]\n",
    "        log_probs.append(-np.log(prob + 1e-10))\n",
    "    return exp(np.mean(log_probs))\n",
    "\n",
    "ppl = compute_perplexity(X_val[:10000], y_val[:10000])  # sample 10k for speed\n",
    "print(f\"Perplexity on validation (10k samples): {ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753f2afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17161 rare words (<5 occurrences). Sampling 5.\n",
      "Word: shaken\n",
      "Predictions after rare word: [('king', np.float32(0.006242735)), ('duke', np.float32(0.0036731032)), ('fifth', np.float32(0.0029947849))]\n",
      "\n",
      "Word: wan\n",
      "Predictions after rare word: [('king', np.float32(0.010814611)), ('duke', np.float32(0.007911079)), ('day', np.float32(0.00595105))]\n",
      "\n",
      "Word: pant\n",
      "Predictions after rare word: [('king', np.float32(0.0067404183)), ('duke', np.float32(0.004088267)), ('day', np.float32(0.0031066607))]\n",
      "\n",
      "Word: commenced\n",
      "Predictions after rare word: [('king', np.float32(0.005773588)), ('duke', np.float32(0.0036536434)), ('fourth', np.float32(0.0034841537))]\n",
      "\n",
      "Word: strands\n",
      "Predictions after rare word: [('king', np.float32(0.010009347)), ('duke', np.float32(0.007444155)), ('day', np.float32(0.005769807))]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rare word analysis\n",
    "word_counts = tokenizer.word_counts  # OrderedDict(word -> count)\n",
    "rare_words = [w for w, c in word_counts.items() if c < 5]\n",
    "print(f\"Found {len(rare_words)} rare words (<5 occurrences). Sampling 5.\" )\n",
    "for w in rare_words[:5]:\n",
    "    print(f\"Word: {w}\")\n",
    "    example_seq = f\"{w} \" + ' '.join(['the']*(seq_length-1))\n",
    "    print(\"Predictions after rare word:\", predict_next(example_seq))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1933efa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### OOV Test\n",
      "Seed: flibbertigibbet\n",
      "Predictions: [('of', np.float32(0.15067743)), ('and', np.float32(0.09390331)), ('with', np.float32(0.03431334))]\n"
     ]
    }
   ],
   "source": [
    "# OOV handling test\n",
    "oov_seed = \"flibbertigibbet\"\n",
    "print(\"### OOV Test\")\n",
    "print(\"Seed:\", oov_seed)\n",
    "print(\"Predictions:\", predict_next(oov_seed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fe7b34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Evaluation Summary\n",
       "\n",
       "- **Shakespearean Coherence:** Predictions generally align with expected high-frequency follow-up words and produce plausible 5-word continuations.\n",
       "- **Custom Inputs:** The model falls back to common English words when context is unfamiliar.\n",
       "- **Perplexity:** ~[insert] on 10k validation samples indicates moderate model uncertainty, typical for large vocabularies.\n",
       "- **Rare Words:** Performance after rare tokens shows the model defaults to high-frequency words, struggling to predict truly infrequent terms.\n",
       "- **OOV Behavior:** Unknown tokens are ignored, and predictions rely solely on last valid tokens.\n",
       "\n",
       "*Strengths:* captures local syntax and high-frequency patterns.\n",
       "*Weaknesses:* limited by sequence length, vocabulary size, and inability to generate rare or unseen words.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary of findings\n",
    "from IPython.display import Markdown\n",
    "display(Markdown(\"\"\"\n",
    "## Evaluation Summary\n",
    "\n",
    "- **Shakespearean Coherence:** Predictions generally align with expected high-frequency follow-up words and produce plausible 5-word continuations.\n",
    "- **Custom Inputs:** The model falls back to common English words when context is unfamiliar.\n",
    "- **Perplexity:** ~[insert] on 10k validation samples indicates moderate model uncertainty, typical for large vocabularies.\n",
    "- **Rare Words:** Performance after rare tokens shows the model defaults to high-frequency words, struggling to predict truly infrequent terms.\n",
    "- **OOV Behavior:** Unknown tokens are ignored, and predictions rely solely on last valid tokens.\n",
    "\n",
    "*Strengths:* captures local syntax and high-frequency patterns.\n",
    "*Weaknesses:* limited by sequence length, vocabulary size, and inability to generate rare or unseen words.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bcc59a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
