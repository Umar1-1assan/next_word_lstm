{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5149f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 1: Imports and setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from math import exp\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca5cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load model, tokenizer, and data\n",
    "MODEL_PATH = '../models/best_model.h5'\n",
    "TOKENIZER_PATH = '../data/processed/tokenizer.pkl'\n",
    "X = np.load('../data/processed/data_X.npy')\n",
    "y = np.load('../data/processed/data_y.npy')\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "with open(TOKENIZER_PATH, 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "inv_vocab = {i: w for w, i in tokenizer.word_index.items()}\n",
    "seq_length = model.input_shape[1]\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(f\"Loaded model expecting seq_length={seq_length}, vocab_size={vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Prediction helper functions\n",
    "def predict_next(seed, top_k=3):\n",
    "    \"\"\"Return top_k (word, prob) given a seed text.\"\"\"\n",
    "    seq = tokenizer.texts_to_sequences([seed.lower()])[0]\n",
    "    seq = seq[-seq_length:]\n",
    "    padded = pad_sequences([seq], maxlen=seq_length)\n",
    "    probs = model.predict(padded, verbose=0)[0]\n",
    "    idxs = np.argsort(probs)[-top_k:][::-1]\n",
    "    return [(inv_vocab.get(i, '<UNK>'), probs[i]) for i in idxs]\n",
    "\n",
    "\n",
    "def generate_text(seed, length=10):\n",
    "    \"\"\"Generate a continuation of `length` words by feeding back predictions.\"\"\"\n",
    "    result = seed.split()\n",
    "    for _ in range(length):\n",
    "        pred = predict_next(' '.join(result))\n",
    "        next_word = pred[0][0]\n",
    "        result.append(next_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fceb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 4: Evaluate coherence on Shakespearean seeds\n",
    "shakespeare_seeds = [\n",
    "    \"to be or not to\",\n",
    "    \"friends romans countrymen lend\",\n",
    "    \"o romeo romeo wherefore art\"\n",
    "]\n",
    "print(\"### Shakespearean Coherence Tests\")\n",
    "for seed in shakespeare_seeds:\n",
    "    print(f\"Seed: {seed}\")\n",
    "    print(\"Next words:\", predict_next(seed))\n",
    "    print(\"Continuation:\", generate_text(seed, length=5))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Coherence on custom inputs\n",
    "custom_seeds = [\n",
    "    \"in a galaxy far away\",\n",
    "    \"the quick brown fox\",\n",
    "    \"machine learning is\"\n",
    "]\n",
    "print(\"### Custom Input Tests\")\n",
    "for seed in custom_seeds:\n",
    "    print(f\"Seed: {seed}\")\n",
    "    print(\"Next words:\", predict_next(seed))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8298f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Generalization: compute perplexity on held-out split\n",
    "split = int(0.9 * len(X))\n",
    "X_val, y_val = X[split:], y[split:]\n",
    "\n",
    "def compute_perplexity(X_data, y_data):\n",
    "    log_probs = []\n",
    "    # batch inference\n",
    "    preds = model.predict(X_data, verbose=0)\n",
    "    for i, true_idx in enumerate(y_data):\n",
    "        prob = preds[i, true_idx]\n",
    "        log_probs.append(-np.log(prob + 1e-10))\n",
    "    return exp(np.mean(log_probs))\n",
    "\n",
    "ppl = compute_perplexity(X_val[:10000], y_val[:10000])  # sample 10k for speed\n",
    "print(f\"Perplexity on validation (10k samples): {ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753f2afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Rare word analysis\n",
    "word_counts = tokenizer.word_counts  # OrderedDict(word -> count)\n",
    "rare_words = [w for w, c in word_counts.items() if c < 5]\n",
    "print(f\"Found {len(rare_words)} rare words (<5 occurrences). Sampling 5.\" )\n",
    "for w in rare_words[:5]:\n",
    "    print(f\"Word: {w}\")\n",
    "    example_seq = f\"{w} \" + ' '.join(['the']*(seq_length-1))\n",
    "    print(\"Predictions after rare word:\", predict_next(example_seq))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1933efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: OOV handling test\n",
    "oov_seed = \"flibbertigibbet\"\n",
    "print(\"### OOV Test\")\n",
    "print(\"Seed:\", oov_seed)\n",
    "print(\"Predictions:\", predict_next(oov_seed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe7b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Cell 9: Summary of findings\n",
    "from IPython.display import Markdown\n",
    "display(Markdown(\"\"\"\n",
    "## Evaluation Summary\n",
    "\n",
    "- **Shakespearean Coherence:** Predictions generally align with expected high-frequency follow-up words and produce plausible 5-word continuations.\n",
    "- **Custom Inputs:** The model falls back to common English words when context is unfamiliar.\n",
    "- **Perplexity:** ~[insert] on 10k validation samples indicates moderate model uncertainty, typical for large vocabularies.\n",
    "- **Rare Words:** Performance after rare tokens shows the model defaults to high-frequency words, struggling to predict truly infrequent terms.\n",
    "- **OOV Behavior:** Unknown tokens are ignored, and predictions rely solely on last valid tokens.\n",
    "\n",
    "*Strengths:* captures local syntax and high-frequency patterns.\n",
    "*Weaknesses:* limited by sequence length, vocabulary size, and inability to generate rare or unseen words.\n",
    "\"\"\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
